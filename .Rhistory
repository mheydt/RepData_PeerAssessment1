fit <- lm(y ~ x1 + x2)
Rprof(NULL)
?rbinom
x
?rnorm
?lm
ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
weight <- c(ctl, trt)
lm.D9 <- lm(weight ~ group)
lm.09
lm.D9
summaryRprof()
weight <- c(ctl, trt)
Rprof()
print(summaryRprof())
ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
weight <- c(ctl, trt)
Rprof()
lm.D9 <- lm(weight ~ group)
Rprof(NULL)
summaryRprof()
?sys.sleep
?Sys.sleep
Rprof()
Sys.Sleep(1)
Rprof(Null)
summaryRprof()
Rprof()
Sys.sleep(1)
Rprof(Null)
summaryRprof()
Rprof()
Sys.sleep(1)
Rprof(NULL)
summaryRprof()
f <- Sys.sleep(1)
Rprof()
f
Rprof(NULL)
summaryRprof()
tail(ames)
load(url("http://s3.amazonaws.com/assets.datacamp.com/course/dasi/ames.RData"))
names(ames)
head(ames)
tail(ames)
area = ames$Gr.Liv.Area
price = ames$SalePrice
# Calculate the summary and draw a histogram of 'area'
summary(area)
hist(area)
samp0 = sample(area, 50)
samp1 = sample(area, 50)
# Draw the histograms:
hist(samp0)
hist(samp1)
# The 'ames' data frame and 'area' and 'price' objects are already loaded
# into the workspace
# Set up an empty vector or 5000 NAs to store sample means:
sample_means50 = rep(NA, 5000)
# Take 5000 samples of size 50 of 'area' and store all of them in
# 'sample_means50'.
for (i in 1:5000) {
samp = sample(area, 50)
sample_means50[i] = mean(samp)
}
# View the result. If you want, you can increase the bin width to show more
# detail by changing the 'breaks' argument.
hist(sample_means50, breaks = 13)
http://s3.amazonaws.com/assets.datacamp.com/course/dasi/evals.RData
load(url("http://s3.amazonaws.com/assets.datacamp.com/course/dasi/evals.RData"))
evals
head(evals)
library(datasets)
data(mtcars)
?mtcats
?mtcars
with(mtcars, tapply(mpg, cal, mean))
sapply(mtcars, cyl, mean)
mean(mtcars$mpg, mtcars$cyl)
tapply(mtcars$cyl, mtcars$mpg, mean)
with(mtcars, tapply(mpg, cyl, mean))
with(mtcars, tapply(mpg, cyl, mean))
with(mtcars, tapply(hp, cyl, mean))
209.21429 - 82.63636
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
x
e
x
?rnorm
?rbinom
print (x)
x <- rnorm(100, mean=5, sd=2)
print (x)
x <- rnorm(100, mean=5, sd=2)
print (x)
x <- rnorm(100, mean=5, sd=2)
print (x)
x <- rnorm(100, mean=5, sd=2)
print (x)
x <- rnorm(100, mean=5, sd=2)
print (x)
set.seed(10)
x <- rnorm(100, mean=5, sd=2)
print (x)
set.seed(10)
x <- rnorm(100, mean=5, sd=2)
print (x)
set.seed(10)
x <- rnorm(100, mean=5, sd=2)
print (x)
set.seed(10)
x <- rnorm(100, mean=5, sd=2)
print (x)
set.seed(10)
x <- rnorm(100, mean=5, sd=2)
print (x)
plot(x)
set.seed(10)
x <- rnorm(100, mean=5, sd=2)
print (x)
plot(x)
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(y)
set.seed(10)
x <- rbinom(100, 10, 0.5)
e <- rnorm(100, 0, 20)
y <- 0.5 + 2 * x + e
plot(y)
set.seed(10)
x <- rbinom(1000, 10, 0.5)
e <- rnorm(1000, 0, 20)
y <- 0.5 + 2 * x + e
plot(y)
set.seed(10)
x <- rbinom(1000, 10, 0.5)
e <- rnorm(1000, 0, 20)
y <- 0.5 + 2 * x + e
plot(y)
print (mean(y))
set.seed(10)
x <- rbinom(1000, 10, 0.5)
e <- rnorm(1000, 0, 20)
y <- 0.5 + 2 * x + e
plot(y)
print (mean(y))
set.seed(10)
x <- rbinom(1000, 10, 0.5)
e <- rnorm(1000, 0, 20)
y <- 0.5 + 2 * x + e
plot(x)
print (mean(y))
set.seed(10)
x <- rbinom(1000, 10, 0.5)
e <- rnorm(1000, 0, 20)
y <- 0.5 + 2 * x + e
plot(e)
print (mean(y))
pnorm(0.1)
pnorm(0.1, 0.5, 0.1)
pnorm(0.1, 0.05, 0.1)
PA = c(38.23, 41.29)
PC = c(41.11, 41.74)
DA = 0.10
RA.total = (PA[2] + DA - PA[1])/PA[1]
RA.total
RC.total = (PC[2] + DA - PC[1])/PC[1]
RC.total
source('~/.active-rstudio-document')
View(sbux_df)
View(sbux_df)
source('~/.active-rstudio-document')
sbuc_ccret
sbux_ccret
sbux
sbux_ccret["12/1/2004",]
names(sbux_ccret)
sbux_ccret
sbux_ccret
sbux_ccret["12/1/2004"]
sbux_ccret["12/1/2005"]
log(-0.1341 + 1)
12 * log(-0.1341 + 1)
(1 - 0.1341) ** 12
(1 - 0.1341) ** 12 - 1
(sbux["December, 2005"] - sbux["December, 2004"]) / sbux["December, 2004"]
?qbeta
qbeta(0.75, 1,1)
qbeta(0.5, 2, 1)
qbeta(0.75, 2, 1)
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
mean(temp)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
class(xyplot(weight ~ Time | Diet, BodyWeight))
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
p
library(datasets)
data(airquality)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
install.packages("ggplot2")
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
g
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth="loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + stats_smooth("loess")
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom="smooth")
?runif
runif
n <- runif(1000)
mean(n)
sd(n)
=1/12
1/12
var(n)
sd(n)^2
for (i in [1:1000])
{
a[i] = runif(100)
}
a = c()
for (i in [1:1000])
{
a[i] = runif(100)
}
a = c()
for (i in 1:1000)
{
a[i] = runif(100)
}
a
a[0]
runif(100)
a = c()
for (i in 1:1000)
{
a[i] = a(,runif(100))
}
a = c()
for (i in 1:1000)
{
a = a[,runif(100)]
}
a = c()
for (i in 1:1000)
{
a = a[,runif(100)]
}
a = c()
for (i in 1:1000)
{
println(i)
a = a[,runif(100)]
}
a = c()
for (i in 1:1000)
{
print(i)
a = a[,runif(100)]
}
a[1] = runif(100)
a[,1] = runif(100)
samples = mtrix(nrow = 1000)
for (i in 1:1000)
{
print(i)
samples[, i] = runif(100)
}
samples = matrix(nrow = 1000)
for (i in 1:1000)
{
print(i)
samples[, i] = runif(100)
}
View(samples)
array
?array
samples = array(dim=2)
samples[1] = c(1, 2, 3)
m = matrix(1000, 100)
View(m)
m = matrix(nrow=1000, ncol=100)
View(m)
m = matrix(0, nrow=1000, ncol=100)
View(m)
mean(m[,1])
samples = matrix(0, nrow=1000, ncol=100)
for (i in 1:1000)
{
samples[, i] = runif(100)
}
samples = matrix(0, nrow=1000, ncol=100)
for (i in 1:1000)
{
samples[i, ] <- runif(100)
}
View(samples)
means = c()
samples = matrix(0, nrow=1000, ncol=100)
for (i in 1:1000)
{
samples[i, ] <- runif(100)
means <- c(means, mean(samples[i,]))
}
sd(means)
mc <- function()
{
means = c()
samples = matrix(0, nrow=1000, ncol=100)
for (i in 1:1000)
{
samples[i, ] <- runif(100)
means <- c(means, mean(samples[i,]))
}
return (sd(means))
}
mc <- function()
{
means = c()
samples = matrix(0, nrow=1000, ncol=100)
for (i in 1:1000)
{
samples[i, ] <- runif(100)
means <- c(means, mean(samples[i,]))
}
return (sd(means))
}
mc()
mc()
mc()
mc()
mc()
mc()
mc()
mc()
mc()
means <- runif(1000)
means
mean(means)
unifs <- runif(1000)
means(unif)
mean(unif)
mean(unifs)
var(unifs)
1/12
sd(unifs)
unifs <- runif(100000)
mean(unifs)
sd(means)
unifs <- runif(100000)
mean(unifs)
sd(unifs)
1/12
sd(unifs)^2
sd(means)
mc <- function()
{
means = c()
samples = matrix(0, nrow=10000, ncol=100)
for (i in 1:10000)
{
samples[i, ] <- runif(100)
means <- c(means, mean(samples[i,]))
}
return (sd(means))
}
mc()
mc()
mc()
mc()
mc()
mc()
1/12
(1/12)^2
(1/12)^0.5
mc <- function()
{
means = c()
samples = matrix(0, nrow=1000000, ncol=100)
for (i in 1:1000000)
{
samples[i, ] <- runif(100)
means <- c(means, mean(samples[i,]))
}
return (sd(means))
}
mc
mc()
mc <- function()
{
means = c()
samples = matrix(0, nrow=100000, ncol=100)
for (i in 1:100000)
{
samples[i, ] <- runif(100)
means <- c(means, mean(samples[i,]))
}
return (sd(means))
}
mc()
?qnorm
dnorm(100, mean=1100, sd=75)
rnorm(100, 1100, 100)
quantile(rnorm(100, 1100, 75))
quantile(0.95, rnorm(100, 1100, 75))
?quantile
summary(quantile(0.95, rnorm(100, 1100, 75)))
summary(quantile(0.95, rnorm(100, 1100, 75)))
b <- rnorm(1000)
pnorm(16,15,10)-pnorm(14,15,10)
qnorm(0.95, 1100, 75)
qnorm(100, 0.95, 1100, 75)
?qnorm
n <-rnorm(100, 1100, 75)
summary(n)
quartile
?quartile
?quartiles
?quantile
quantile(0.95, n)
n
quantile(n)
quantile(n, 0.95)
ppois(10, 15)
?pnorm
(16 - 15) / (10 / sqrt(100))
(14 - 15) / (10 / sqrt(100))
pnorm(1, mean = 15, sd=10)
pnorm(-1, mean = 15, sd=10)
pnorm(1, mean = 15, sd=10) - pnorm(-1, mean = 15, sd=10)
?qnorm(0.95)
qnorm(0.95)
1.96*150+1100
1.96*750+1100
(1.96*75)+1100
qnorm(0.95)
qnorm(0.95)*7.5 + 1100
.2*.8
qnorm(0.9)
qnorm(0.95)*7.5 + 1100
```{r}
?ggplot
?ggplot
library(ggplot2)
?ggplot
d = read.csv("activity.csv")
setwd("~/Documents/Coursera/Data Science Specialization/Reproducable Research/RepData_PeerAssessment1")
d = read.csv("activity.csv")
unique(d$date)
aggregate(steps ~ date, d, median)
View(d)
d[d$date=="2012-10-04"]
d[date=="2012-10-04"]
d[date==as.Date("2012-10-04")]
d[d$date==as.Date("2012-10-04")]
class(d$date)
d$date2 <- as.Date(d$date)
class(d$date2)
read.xsv
?read.csv
View(d)
d = read.csv("activity.csv", colClasses=c("Numeric", "Date", "Numeric"))
d = read.csv("activity.csv", header=TRUE, colClasses=c("Numeric", "Date", "Numeric"))
d = read.csv("activity.csv", header=TRUE, colClasses=c("numeric", "Date", "Numeric"))
d = read.csv("activity.csv", header=TRUE, colClasses=c("numeric", "Date", "numeric"))
View(d)
class(d$steps)
class(d$date)
d = read.csv("activity.csv", header=FALSE, colClasses=c("numeric", "Date", "numeric"))
aggregate(steps ~ date, d, median)
d[d$date=="2012-10-23"]
d[d$date=="2012-10-23",]
order(d, d[d$date=="2012-10-23",]
)
?order
d$steps
d[d$date=="2012-10-23",]
d[d$date=="2012-10-23",]$steps
median(d[d$date=="2012-10-23",]$steps)
median(order(d[d$date=="2012-10-23",]$steps))
unique(d$date)
length(unique(d$date))
meanStepsByDay <- aggregate(steps ~ date, d, mean)
View(meanStepsByDay)
?summary
